{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CkMLtxt0ZNH1bO6lmZOAOpjJUf84kgQ9",
      "authorship_tag": "ABX9TyO5uPqwEh0uFzZjROqq2vqB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedamusk/earthquakes-and-Python/blob/main/earthquake_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cartopy basemap requests beautifulsoup4"
      ],
      "metadata": {
        "id": "gPQ0crm2nozt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "outputId": "f2679725-e7e3-46c4-b19a-d8cd9b4e54c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cartopy\n",
            "  Downloading Cartopy-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Collecting basemap\n",
            "  Downloading basemap-1.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from cartopy) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.7.1)\n",
            "Requirement already satisfied: shapely>=1.7 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.0.6)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from cartopy) (24.1)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.6.1)\n",
            "Collecting basemap-data<1.4,>=1.3.2 (from basemap)\n",
            "  Downloading basemap_data-1.3.2-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting packaging>=20 (from cartopy)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5->cartopy) (1.16.0)\n",
            "Downloading Cartopy-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading basemap-1.4.1-cp310-cp310-manylinux1_x86_64.whl (935 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m936.0/936.0 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading basemap_data-1.3.2-py2.py3-none-any.whl (30.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: packaging, basemap-data, cartopy, basemap\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "Successfully installed basemap-1.4.1 basemap-data-1.3.2 cartopy-0.23.0 packaging-23.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "mpl_toolkits"
                ]
              },
              "id": "84c3e157e060427c9012468861fd2221"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests #for making HTTP requests to web servers\n",
        "from bs4 import BeautifulSoup #for parsing HTML and XML documents\n",
        "import pandas as pd#For dat manipulation and analysis\n",
        "import datetime#for manipulating dates and times\n",
        "from sklearn.model_selection import GridSearchCV#For hyperparameter tuning in machine learning models\n",
        "from imblearn.pipeline import Pipeline#for constructing a machine learning workflow with steps for data preprocessing and modelling\n",
        "from imblearn.over_sampling import SMOTE#for handling imbalanced datasets by oversampling the minority class\n",
        "from sklearn.model_selection import train_test_split#for splitting the dataset into training and testing sets\n",
        "from sklearn.ensemble import RandomForestClassifier#for building the earthquake prediction model\n",
        "from sklearn.metrics import classification_report, accuracy_score#for evaluating the perfomance of the machine learning model\n",
        "import seaborn as sns#for creating attractive and informative statistical graphics\n",
        "import matplotlib.pyplot as plt#for plotting graphs and charts\n",
        "import folium#for creating interactive maps\n",
        "from folium.plugins import MarkerCluster#for clustering earthquake locations on the map for better readability"
      ],
      "metadata": {
        "id": "u0TeZobEor0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_earthquake_data():\n",
        "  #this line defines a function\n",
        "  url='https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv'\n",
        "  #this line defines the variable 'url' and assigns the url of a csv file containing earthquake data form the USGS website\n",
        "  response=requests.get(url)\n",
        "  #this line uses the requests library ro send a GET request to the specified url\n",
        "  if response.status_code==200:\n",
        "    #this line checks the status code of the response. A status code of 200 indicates a succesful request\n",
        "    data=pd.read_csv(url)\n",
        "    #if the status code is 200, this line uses the pandas library to read the CSV data from the URL into a Pandas DataFrame object named data\n",
        "    return data\n",
        "    #if succesful this line returns the 'data' DataFrame from the function\n",
        "  else:\n",
        "    print(f\"Failed to retrieve dta. Status code:{response.status_code}\")\n",
        "    return None\n",
        "    #if the status code is not 200, and error message is printed\n",
        "\n",
        "\n",
        "    earthquake_data=scrape_earthquake_data()\n",
        "\n",
        "\n",
        "    if earthquake_data is not None:\n",
        "      print(earthquake_data.head())\n",
        "    else:\n",
        "      print(\"No earthquake data retrieved\")\n",
        "      #Displays the first few rows of the dataset"
      ],
      "metadata": {
        "id": "yR4A-6MisRK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "def preprocess_data(df):\n",
        "    df = df[['time', 'latitude', 'longitude', 'depth', 'mag', 'place']]\n",
        "    df.columns = ['Time', 'Latitude', 'Longitude', 'Depth', 'Magnitude', 'Location']\n",
        "    # Select relevant columns and rename them for consistency\n",
        "\n",
        "    df['Time'] = pd.to_datetime(df['Time'])\n",
        "    # Convert time to datetime\n",
        "\n",
        "    df['Year'] = df['Time'].dt.year\n",
        "    df['Month'] = df['Time'].dt.month\n",
        "    df['Day'] = df['Time'].dt.day\n",
        "    df['Hour'] = df['Time'].dt.hour\n",
        "    df['Minute'] = df['Time'].dt.minute\n",
        "    df['Second'] = df['Time'].dt.second\n",
        "    # Extract additional features from the datetime column\n",
        "\n",
        "    df = df.dropna()\n",
        "    # Handle missing values if any\n",
        "\n",
        "    return df\n",
        "    #return the processed DataFrame\n",
        "\n",
        "\n",
        "earthquake_data = scrape_earthquake_data()\n",
        "if earthquake_data is not None:\n",
        "    processed_data = preprocess_data(earthquake_data)\n",
        "    print(processed_data.head())\n",
        "else:\n",
        "    print(\"No earthquake data retrieved\")\n",
        "    #applying the preprocessing function and displaying the data"
      ],
      "metadata": {
        "id": "i9bIeD8itqCF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "385aba2e-d2f8-49e3-aa1a-c9400f7c10de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'scrape_earthquake_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-627a7ca38884>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mearthquake_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_earthquake_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mearthquake_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mearthquake_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'scrape_earthquake_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JrxpY4AyzZog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#importing required libraries\n",
        "\n",
        "def plot_magnitude_distribution(df):\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    #setting up the plot\n",
        "\n",
        "    sns.histplot(df['Magnitude'], bins=30, color='cornflowerblue', edgecolor='black', linewidth=1.2)\n",
        "    # Create the histogram with KDE plot using blue hues\n",
        "\n",
        "    mean_magnitude = df['Magnitude'].mean()\n",
        "    plt.axvline(mean_magnitude, color='red', linestyle='--', linewidth=2)\n",
        "    plt.text(mean_magnitude + 0.1, plt.ylim()[1] * 0.8, f'Mean: {mean_magnitude:.2f}', color='red', fontsize=14, fontweight='bold')\n",
        "    # Add a vertical line at the mean magnitude\n",
        "\n",
        "    median_magnitude = df['Magnitude'].median()\n",
        "    plt.axvline(median_magnitude, color='green', linestyle='--', linewidth=2)\n",
        "    plt.text(median_magnitude + 0.1, plt.ylim()[1] * 0.8, f'Median: {median_magnitude:.2f}', color='green', fontsize=14, fontweight='bold')\n",
        "    # Add a vertical line at the median magnitude\n",
        "\n",
        "    plt.title('Distribution of Earthquake Magnitudes', fontsize=20, fontweight='bold', color='navy')\n",
        "    plt.xlabel('Magnitude', fontsize=16, fontweight='bold')\n",
        "    plt.ylabel('Frequency', fontsize=16, fontweight='bold')\n",
        "    # Customizing the title and labels\n",
        "\n",
        "    plt.xticks(fontsize=12, fontweight='bold')\n",
        "    plt.yticks(fontsize=12, fontweight='bold')\n",
        "    # Customize the tick parameters\n",
        "\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    # Add custom grid\n",
        "\n",
        "    plt.axvspan(5, 7, color='red', alpha=0.3, lw=0)\n",
        "    plt.text(6, plt.ylim()[1] * 0.95, 'Critical Range (5-7)', color='navy', fontsize=14, fontweight='bold', ha='center')\n",
        "    # Highlight a critical magnitude range\n",
        "\n",
        "    max_freq_bin = df['Magnitude'].value_counts().idxmax()\n",
        "    max_freq_count = df['Magnitude'].value_counts().max()\n",
        "    plt.annotate(f'Highest Frequency\\n{max_freq_bin} Mag: {max_freq_count} times',\n",
        "                 xy=(max_freq_bin, df['Magnitude'].value_counts()[max_freq_bin]),\n",
        "                 xytext=(max_freq_bin + 0.5, df['Magnitude'].value_counts()[max_freq_bin] + 5),\n",
        "                 arrowprops=dict(facecolor='black', shrink=0.05),\n",
        "                 fontsize=14, fontweight='bold',\n",
        "                 bbox=dict(boxstyle=\"round, pad=0.3\", edgecolor='black', facecolor=\"lightgray\", alpha=0.8))\n",
        "    # Adding annotations for the highest frequency bin\n",
        "\n",
        "    plt.show()\n",
        "    # Display the plot\n",
        "    plot_magnitude_distribution(processed_data)\n"
      ],
      "metadata": {
        "id": "kyt5U6ZoNsQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "from folium.plugins import MarkerCluster\n",
        "#Importing required Libaries\n",
        "def plot_enhanced_geo_map(df):\n",
        "    m = folium.Map(location=[df['Latitude'].mean(), df['Longitude'].mean()], zoom_start=2)\n",
        "    # Initialize the map centered around the mean coordinates\n",
        "\n",
        "    marker_cluster = MarkerCluster().add_to(m)\n",
        "    # Create a marker cluster\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "      #Looping through the DataFrame to Add markers\n",
        "        magnitude = row['Magnitude']\n",
        "        if magnitude < 3.0:\n",
        "            color = 'blue'\n",
        "        elif 3.0 <= magnitude < 5.0:\n",
        "            color = 'green'\n",
        "        elif 5.0 <= magnitude < 7.0:\n",
        "            color = 'orange'\n",
        "        else:\n",
        "            color = 'red'\n",
        "        #Determining Marker Color based on Magnitude\n",
        "\n",
        "        folium.CircleMarker(\n",
        "            location=[row['Latitude'], row['Longitude']],\n",
        "            radius=5,\n",
        "            popup=(\n",
        "                f\"Location: {row['Location']}<br>\"\n",
        "                f\"Time: {row['Time']}<br>\"\n",
        "                f\"Magnitude: {row['Magnitude']}<br>\"\n",
        "                f\"Depth: {row['Depth']} km\"\n",
        "            ),\n",
        "            color=color,\n",
        "            fill=True,\n",
        "            fill_color=color,\n",
        "            fill_opacity=0.7\n",
        "        ).add_to(marker_cluster)\n",
        "        #adding Markers to the map\n",
        "\n",
        "    return m\n",
        "    #returning the map\n",
        "\n",
        "\n",
        "enhanced_earthquake_map = plot_enhanced_geo_map(processed_data)\n",
        "enhanced_earthquake_map.save('enhanced_earthquake_map.html')\n",
        "enhanced_earthquake_map\n"
      ],
      "metadata": {
        "id": "aZBfRsJsNpvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TFZphFcPuDPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "#importing required libraries\n",
        "\n",
        "def build_and_evaluate_model_with_smote(df):\n",
        "    features = ['Latitude', 'Longitude', 'Depth', 'Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']\n",
        "    target = 'Magnitude'\n",
        "    #selecting features and target variable\n",
        "\n",
        "    df['Target'] = (df['Magnitude'] >= 5.0).astype(int)\n",
        "    # Create the target variable\n",
        "\n",
        "    X = df[features]\n",
        "    y = df['Target']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    #splitting the data into Training and Testing sets\n",
        "\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "    #handling class imbalance with SMOTE\n",
        "\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train_res, y_train_res)\n",
        "    #training the random forest model\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    #making predictions and evaluating the model\n",
        "\n",
        "    return accuracy, report, y_test, y_pred\n",
        "    #returning the results\n",
        "\n",
        "\n",
        "accuracy, report, y_test, y_pred = build_and_evaluate_model_with_smote(processed_data)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "id": "ut1sjjKJHnGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yqWLeh5OuEuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bLsgFGZsuZIA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yw1lFPBAuPQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rRa_EbwlwJpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7pFGK9eXwq2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3JAVeNBswvoU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}